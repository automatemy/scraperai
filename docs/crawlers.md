
However, when facing scraping tasks, additional needs may arise, such as:
- Emulating human interactions (e.g., clicking, scrolling).
- Capturing webpage screenshots.
- Evading anti-scraping measures.


# Crawler
Crawler primary goal is to retrieve webpage content. 
Therefore, various web tools can be employed, including as requests, httpx, aiohttp, Selenium, Playwright and others.

However, when facing scraping tasks, additional needs may arise, such as:
- Emulating human interactions (e.g., clicking, scrolling).
- Capturing webpage screenshots.
- Evading anti-scraping measures.

In such cases, automated testing software like Selenium or Playwright is the preferred option. 
We opt for Selenium webdrivers as the default tool due to its convenience, user-friendly nature, and effective techniques for circumventing most website blocks.

## SeleniumCrawler

## RequestsCrawler

## Custom Crawler
